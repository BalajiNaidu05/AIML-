{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BalajiNaidu05/AIML-PROJECT/blob/main/Aiml_proj_code1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FCM8dZOWUZN",
        "outputId": "be092c0f-6d48-4c62-a854-1be6054da9c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      0.20      0.33         5\n",
            "    positive       0.56      1.00      0.71         5\n",
            "\n",
            "    accuracy                           0.60        10\n",
            "   macro avg       0.78      0.60      0.52        10\n",
            "weighted avg       0.78      0.60      0.52        10\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "# stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# dataset\n",
        "data = {\n",
        "    'text': [\n",
        "        'I love this product', 'This is the best thing ever', 'Amazing quality and great service',\n",
        "        'Highly recommend this', 'I hate this product', 'This is the worst thing ever',\n",
        "        'Terrible quality and awful service', 'Never recommend this',\n",
        "        'The movie was fantastic', 'I had a wonderful time', 'The food was absolutely delicious',\n",
        "        'Worst experience ever', 'Awful product, waste of money', 'Fantastic service, highly recommend',\n",
        "        'I will never buy this again', 'I am so happy with my purchase', 'It’s the worst meal I’ve had',\n",
        "        'The customer service was great', 'This is such a disappointment', 'I absolutely love the design',\n",
        "    ],\n",
        "    'label': [\n",
        "        'positive', 'positive', 'positive', 'positive', 'negative', 'negative',\n",
        "        'negative', 'negative', 'positive', 'positive', 'positive', 'negative',\n",
        "        'negative', 'positive', 'negative', 'positive', 'negative', 'positive',\n",
        "        'negative', 'positive'\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Text Preprocessing (to retain enough words for classification)\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())  # Convert to lowercase and tokenize\n",
        "    tokens = [word for word in tokens if word not in string.punctuation]  # Remove punctuation\n",
        "    # Removed stopword filtering to retain important words like 'love' and 'hate'\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "df['text_clean'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "# Train-test split (ensuring a balanced split for positive and negative samples)\n",
        "X = df['text_clean']\n",
        "y = df['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42, stratify=y)\n",
        "\n",
        "# Feature Extraction using TF-IDF\n",
        "tfidf = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# Train the Naive Bayes Model\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = nb.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\n"
      ]
    }
  ]
}